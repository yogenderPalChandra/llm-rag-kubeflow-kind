apiVersion: v1
kind: Pod
metadata:
  name: ollama-pod
  namespace: ollama
spec:
  containers:
  - name: ollama
    image: yogender027/ollama-custom:no_entrypoint
    command: ["/bin/sh", "-c"]
    args:
      - |
        echo "[INFO] Starting ollama serve in background..." && \
        ollama serve > /tmp/ollama.log 2>&1 & \
        until bash -c 'exec 3<>/dev/tcp/localhost/11434; echo $?' > /dev/null 2>&1; do \
          echo "[INFO] Waiting for ollama to be ready..."; sleep 2; \
        done && \
        echo "[INFO] Pulling llama3..." && \
        ollama pull llama3 && \
        echo "[INFO] Ollama server is running in background, keeping the container alive..." && \
        tail -f /tmp/ollama.log
    ports:
    - containerPort: 11434
    env:
    - name: OLLAMA_HOST
      value: "0.0.0.0:11434"
    volumeMounts:
    - mountPath: /root/.ollama
      name: ollama-storage
    resources:
      limits:
        memory: "8Gi"
        cpu: "8"
      requests:
        memory: "6Gi"
        cpu: "4"
  volumes:
    - name: ollama-storage
      persistentVolumeClaim:
        claimName: ollama-pvc
